{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoOw09Ib-qvR"
      },
      "outputs": [],
      "source": [
        "# importing necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "%matplotlib inline \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"phishing_detection.csv\")"
      ],
      "metadata": {
        "id": "6LuiudS--3WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "# result is the target attribute"
      ],
      "metadata": {
        "id": "Au2lmvwp-3o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "# result is the target attribute"
      ],
      "metadata": {
        "id": "9spGmg59_AKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "Xxq7xEyP_AS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "4zo1XuSu_AUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# no null values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "1NNlsf_u_AXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,6))\n",
        "# count numbers of class records for 'Result' target attribute\n",
        "sns.countplot('Result', data = df)"
      ],
      "metadata": {
        "id": "w8ilJuiK_AYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Result'].value_counts()"
      ],
      "metadata": {
        "id": "vOexGFVn_Abu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we can see the target class count is almost equally balanced. Hence Data augmentation is necessary\n",
        "\n",
        "#Module1"
      ],
      "metadata": {
        "id": "xgcLOYCc_Ac6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating correlation matrix on the features \n",
        "corrmat = df.corr()\n",
        "top_corr_features = corrmat.index\n",
        "plt.figure(figsize=(30, 25))\n",
        "# representation of correalation matrix through heatmap\n",
        "g = sns.heatmap(df[top_corr_features].corr(), annot = True, cmap = \"RdYlGn\")"
      ],
      "metadata": {
        "id": "Xj7PNDBa_Afx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_corr = set() # Set of all the names of deleted columns\n",
        "def correlation(dataset, threshold):\n",
        "  corr_matrix = dataset.corr()\n",
        "  for i in range(len(corr_matrix.columns)):\n",
        "      for j in range(i):\n",
        "          if (abs(corr_matrix.iloc[i, j]) >= threshold) and (corr_matrix.columns[j] not in col_corr):\n",
        "              colname = corr_matrix.columns[i] # getting the name of column\n",
        "              col_corr.add(colname)"
      ],
      "metadata": {
        "id": "Anh647Us_AjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove multicollinear column with collinearity greater than 0.85\n",
        "correlation(df, 0.85)\n",
        "col_corr"
      ],
      "metadata": {
        "id": "pyyFfWSH_Akn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{'popUpWidnow'}"
      ],
      "metadata": {
        "id": "QBrDRadO_Ano"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# identifying weakly correlated features with target attribute\n",
        "weak_col_corr = set()\n",
        "def weakcorrelation(dataset, threshold):\n",
        "  corr_matrix = dataset.corr()\n",
        "  idx = 0\n",
        "  for feature in corr_matrix['Result']:\n",
        "    if(feature < threshold):\n",
        "      weak_col_corr.add(corr_matrix.columns[idx])\n",
        "    idx += 1\n",
        "  \n",
        " # dropping features with correlation less than 0.01 \n",
        "weakcorrelation(df, 0.01)\n",
        "print(weak_col_corr)"
      ],
      "metadata": {
        "id": "2QdFgZ5t_ApB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gathering all columns that were identified to be deleted\n",
        "del_col = col_corr.union(weak_col_corr)\n",
        "del_col"
      ],
      "metadata": {
        "id": "rzhdzLAj_Ase"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping columns permanantly\n",
        "df.drop(del_col, axis = 1, inplace = True)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "hsZnzU_XAcYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting dataset into train and test"
      ],
      "metadata": {
        "id": "VSg6lIadAcZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "\n",
        "# input attribute and target attribute\n",
        "X = df.iloc[: , :-1]\n",
        "y = df.iloc[:, -1:]\n",
        "\n",
        "y"
      ],
      "metadata": {
        "id": "DluaBH1CAcdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split with test size as 0.25 \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
      ],
      "metadata": {
        "id": "57KgPmGoAceR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Module 2: Decision tree classifier"
      ],
      "metadata": {
        "id": "VfyeuzfOAchY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "tC8ujJznAciT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "IlwIazSBAcls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "g1T_xv0eAcmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize decision tree"
      ],
      "metadata": {
        "id": "jHp0JhL8BDiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from six import StringIO\n",
        "from IPython.display import Image\n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file= dot_data, feature_names=list(X.columns), filled = True, rounded=True)\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
        "\n",
        "Image(graph.create_png())"
      ],
      "metadata": {
        "id": "RZEDnyREBDjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "# classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "lsb3cfOWBDm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion matrix for decision tree model\n",
        "\n",
        "#A confusion matrix is a summary of prediction results on a classification problem.\n",
        "\n",
        "#The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix."
      ],
      "metadata": {
        "id": "Mbk86qBFBDn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "img = cv2.imread('confusion.png', cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "OdIyIqa4BDq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the confusion matrix for our model\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "Ze6bdOdBBDr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot = True, fmt='0.0f')"
      ],
      "metadata": {
        "id": "hdBGVw4ZBD0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest"
      ],
      "metadata": {
        "id": "qj-I7Du-BD6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction on validation dataset\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# prediction on training dataset\n",
        "y_pred_train = rfc.predict(X_train)\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"Train ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_train, y_pred_train))"
      ],
      "metadata": {
        "id": "NF5B-TotBtPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "c4QFWcf7BtTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "lpqW_SWYBtUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "TSr0uQkLBtXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot = True, fmt='0.0f')"
      ],
      "metadata": {
        "id": "IGJdAwg5BtYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "tRqC190DCO7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "# Building a Support Vector Machine on train data\n",
        "svc_model = SVC(C= .1, gamma= 1, kernel='sigmoid', random_state=42)\n",
        "\n",
        "svc_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "bY7AjjDRBtbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rediction = svc_model .predict(X_test)\n",
        "# check the accuracy on the training set\n",
        "print('Accuracy of training data: ', svc_model.score(X_train, y_train))\n",
        "print('Accuracy of validation data: ',svc_model.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "ip_aJZhOCRfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "# generating classification report\n",
        "print(classification_report(y_test, prediction))"
      ],
      "metadata": {
        "id": "VIraapw9CRg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, prediction)"
      ],
      "metadata": {
        "id": "R_9dHXdECRjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test, prediction), annot = True, fmt='0.0f')"
      ],
      "metadata": {
        "id": "L2oQdlZ1CRlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#K-nearest Neighbors"
      ],
      "metadata": {
        "id": "_13x0CeyCRn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "zqCOirbWCRpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#choosing the best values of k (neighbours)"
      ],
      "metadata": {
        "id": "6YTXKAypCrdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neighbour = []\n",
        "accuracy = []\n",
        "for k in range(1, 20):\n",
        "  k_near = KNeighborsClassifier(n_neighbors=k)\n",
        "  k_near.fit(X,y)\n",
        "  Y_pre_test = k_near.predict(X_test)\n",
        "  Y_pre_train = k_near.predict(X_train)\n",
        "  test_accurry = accuracy_score(Y_pre_test, y_test)\n",
        "  neighbour.append(k)\n",
        "  accuracy.append(test_accurry)"
      ],
      "metadata": {
        "id": "Sm43UjvFCrew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting for n neighbour vs accuracy\n",
        "plt.plot(neighbour, accuracy)\n",
        "plt.title('n neighbour vs accuracy')\n",
        "plt.xlabel('n neighbour')\n",
        "plt.ylabel('accuracy')"
      ],
      "metadata": {
        "id": "XPsxGRMkCriH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN with n_neighbour = 1"
      ],
      "metadata": {
        "id": "N_Y74h6cCrjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_near = KNeighborsClassifier(n_neighbors=1)\n",
        "k_near.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "HRWpl_DPCrmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pre_test = k_near.predict(X_test)\n",
        "Y_pre_train = k_near.predict(X_train)"
      ],
      "metadata": {
        "id": "7nOvV6_dCrn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "train_accurry = accuracy_score(Y_pre_train, y_train)\n",
        "test_accurry = accuracy_score(Y_pre_test, y_test)\n",
        "print('Accuracy for train dataset for K-neariest : ', train_accurry)\n",
        "print('Accuracy for test dataset for K-neariest : ', test_accurry)"
      ],
      "metadata": {
        "id": "YVcS9T49CrsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(classification_report(y_test, Y_pre_test ))"
      ],
      "metadata": {
        "id": "ZvijQpmVDXQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, Y_pre_test )"
      ],
      "metadata": {
        "id": "94CVThwODXSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test, Y_pre_test), annot = True, fmt='0.0f')"
      ],
      "metadata": {
        "id": "_rdgCfmCDXVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "xNUVajLiDXWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "MGhyNijaDXbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgr = LogisticRegression(random_state=0)\n",
        "lgr.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "mJE6X9nfDXfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pre_test = lgr.predict(X_test)\n",
        "y_pre_train = lgr.predict(X_train)"
      ],
      "metadata": {
        "id": "vwiheFFXDXgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "train_accurry = accuracy_score(y_pre_train, y_train)\n",
        "test_accurry = accuracy_score(y_pre_test, y_test)\n",
        "print('Accuracy for train dataset for logistic reg : ', train_accurry)\n",
        "print('Accuracy for test dataset for logistic reg : ', test_accurry)"
      ],
      "metadata": {
        "id": "W2hrc3CwDXj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(classification_report(y_test, y_pre_test ))"
      ],
      "metadata": {
        "id": "bTtFrpAxDXk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pre_test )"
      ],
      "metadata": {
        "id": "XyVcAkouBtcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test,y_pre_test), annot = True, fmt='0.0f')"
      ],
      "metadata": {
        "id": "Q6Dc3GVjBtgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes"
      ],
      "metadata": {
        "id": "De7y5dgvEQIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB, BernoulliNB, ComplementNB"
      ],
      "metadata": {
        "id": "pF19-t_dEQJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bernoullis Navaive bayes classifier\n",
        "nvb = BernoulliNB()\n",
        "nvb.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Qanj0zg8EQMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pre_test = nvb.predict(X_test)\n",
        "y_pre_train = nvb.predict(X_train)"
      ],
      "metadata": {
        "id": "p42thmV7EQNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "train_accurry = accuracy_score(y_pre_train, y_train)\n",
        "test_accurry = accuracy_score(y_pre_test, y_test)\n",
        "print('Accuracy for train dataset for naive bayes  reg : ', train_accurry)\n",
        "print('Accuracy for test dataset for naive bayes reg : ', test_accurry)"
      ],
      "metadata": {
        "id": "ah0xP6VtEQQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(classification_report(y_test, y_pre_test ))"
      ],
      "metadata": {
        "id": "i2qwC6DMEQRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pre_test)"
      ],
      "metadata": {
        "id": "TTFNJtl4EQVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test, y_pre_test), annot = True, fmt='0.0f')"
      ],
      "metadata": {
        "id": "AywuLyv3FAnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adaboost"
      ],
      "metadata": {
        "id": "2ueIejY3FA06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Create Decision Tree classifer object\n",
        "clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "mR1kHRiHFA2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "XiGBjkDuFA7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "duocotflFA8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "zsrbfAQfFBJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot = True, fmt='0.0f')"
      ],
      "metadata": {
        "id": "uM52FVObFBXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hybrid Ensembler\n",
        "#Ensembler method used - Max voting: It is mainly used for classification problems. \n",
        "#The method consists of building multiple models independently and getting their individual output called ‘vote’. \n",
        "#The class with maximum votes is returned as output."
      ],
      "metadata": {
        "id": "DDCrM4MCFexX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing voting classifier\n",
        "from sklearn.ensemble import VotingClassifier"
      ],
      "metadata": {
        "id": "zMokIOSsFey-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = RandomForestClassifier(n_estimators=100)\n",
        "model_2 = KNeighborsClassifier(n_neighbors=1)\n",
        "model_3 = LogisticRegression(random_state=0)\n",
        "model_4 = BernoulliNB()\n",
        "model_5 = DecisionTreeClassifier()\n",
        "ensemble = VotingClassifier(estimators=[('RandomForest', model_1), ('KNN', model_2), ('LogisticRegression', model_3), ('NaiveBayes', model_4),\n",
        "                                        ('DT', model_5)], voting='hard')"
      ],
      "metadata": {
        "id": "d9WfdxSxFe2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble.fit(X_train, y_train)\n",
        "y_pred_test = ensemble.predict(X_test)\n",
        "y_pred_train = ensemble.predict(X_train)"
      ],
      "metadata": {
        "id": "8FC-pi2XF3DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "train_accurry = accuracy_score(y_pred_train, y_train)\n",
        "test_accurry = accuracy_score(y_pred_test, y_test)\n",
        "print('Accuracy for train dataset for naive bayes  reg : ', train_accurry)\n",
        "print('Accuracy for test dataset for naive bayes reg : ', test_accurry)"
      ],
      "metadata": {
        "id": "HACJMvegF3IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(ensemble, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "WLlpoJO0F3JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phising = ensemble.predict(input)"
      ],
      "metadata": {
        "id": "t9jk6ZLUGK5D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}